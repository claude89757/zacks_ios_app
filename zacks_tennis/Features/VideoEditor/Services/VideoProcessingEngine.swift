//
//  VideoProcessingEngine.swift
//  zacks_tennis
//
//  æ ¸å¿ƒè§†é¢‘å¤„ç†å¼•æ“ - ä¼˜åŒ–ç‰ˆæœ¬
//  æ”¯æŒåˆ†æ®µå¤„ç†ã€å†…å­˜ä¼˜åŒ–ã€æ–­ç‚¹ç»­ä¼ 
//

import Foundation
import AVFoundation
import CoreImage
import UIKit
import SwiftData

/// è§†é¢‘å¤„ç†å¼•æ“ - æ ¸å¿ƒå¤„ç†é€»è¾‘
@MainActor
@Observable
final class VideoProcessingEngine: VideoProcessing {

    // MARK: - Properties

    /// å¤„ç†è¿›åº¦å›è°ƒ
    var onProgressUpdate: ((ProcessingProgress) -> Void)?

    /// æ–°å›åˆæ£€æµ‹å›è°ƒï¼ˆå®æ—¶æµå¼æ›´æ–°ï¼‰
    var onRallyDetected: ((VideoHighlight) -> Void)?

    /// æ˜¯å¦æ­£åœ¨å¤„ç†
    private(set) var isProcessing = false

    /// Vision åˆ†æå™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let visionAnalyzer: any FrameAnalyzing

    /// éŸ³é¢‘åˆ†æå™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let audioAnalyzer: any AudioAnalyzing

    /// ç½‘çƒè¿½è¸ªåˆ†æå™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let ballTracker: (any BallTracking)?

    /// ç½‘çƒå¯è§†åŒ–å¼•æ“ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let ballVisualizer: (any BallVisualizing)?

    /// çŠ¶æ€ç®¡ç†å™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let stateManager: any ProcessingStateManaging

    /// å›åˆæ£€æµ‹å¼•æ“ï¼ˆéŸ³é¢‘èšç±»ï¼‰
    private let rallyDetectionEngine: RallyDetectionEngine

    // MARK: - Constants

    /// å¤„ç†é…ç½®
    private let config = ProcessingConfiguration()

    // MARK: - Initialization

    /// åˆå§‹åŒ–å¤„ç†å¼•æ“ï¼ˆæ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    /// - Parameters:
    ///   - visionAnalyzer: Vision åˆ†æå™¨
    ///   - audioAnalyzer: éŸ³é¢‘åˆ†æå™¨
    ///   - ballTracker: ç½‘çƒè¿½è¸ªåˆ†æå™¨ï¼ˆå¯é€‰ï¼‰
    ///   - ballVisualizer: ç½‘çƒå¯è§†åŒ–å¼•æ“ï¼ˆå¯é€‰ï¼‰
    ///   - stateManager: çŠ¶æ€ç®¡ç†å™¨
    ///   - rallyDetectionEngine: å›åˆæ£€æµ‹å¼•æ“ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    init(
        visionAnalyzer: any FrameAnalyzing,
        audioAnalyzer: any AudioAnalyzing,
        ballTracker: (any BallTracking)? = nil,
        ballVisualizer: (any BallVisualizing)? = nil,
        stateManager: any ProcessingStateManaging,
        rallyDetectionEngine: RallyDetectionEngine? = nil
    ) {
        self.visionAnalyzer = visionAnalyzer
        self.audioAnalyzer = audioAnalyzer
        self.ballTracker = ballTracker
        self.ballVisualizer = ballVisualizer
        self.stateManager = stateManager
        self.rallyDetectionEngine = rallyDetectionEngine ?? RallyDetectionEngine()
    }

    /// ä¾¿åˆ©åˆå§‹åŒ–å™¨ - ä½¿ç”¨é»˜è®¤å®ç°ï¼ˆåŒ…å«ç½‘çƒè¿½è¸ªï¼‰
    convenience init(enableBallTracking: Bool = true) {
        let tracker: (any BallTracking)? = if enableBallTracking {
            BallTrackingAnalyzer()
        } else {
            nil
        }

        let visualizer: (any BallVisualizing)? = if enableBallTracking {
            BallVisualizationEngine()
        } else {
            nil
        }

        self.init(
            visionAnalyzer: VisionAnalyzer(),
            audioAnalyzer: AudioAnalyzer(),
            ballTracker: tracker,
            ballVisualizer: visualizer,
            stateManager: ProcessingStateManager.shared
        )
    }

    // MARK: - Public Methods

    /// å¤„ç†è§†é¢‘å¹¶æ£€æµ‹å›åˆï¼ˆåè®®å®ç°ï¼‰
    /// - Parameter video: è¦å¤„ç†çš„è§†é¢‘æ¨¡å‹
    /// - Returns: æ£€æµ‹åˆ°çš„å›åˆæ•°ç»„
    func processVideo(_ video: Video) async throws -> [VideoHighlight] {
        return try await processVideo(video, resumeFromState: nil)
    }

    /// å¤„ç†è§†é¢‘å¹¶æ£€æµ‹å›åˆï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    /// - Parameters:
    ///   - video: è¦å¤„ç†çš„è§†é¢‘æ¨¡å‹
    ///   - resumeFromState: å¯é€‰çš„æ¢å¤çŠ¶æ€ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
    /// - Returns: æ£€æµ‹åˆ°çš„å›åˆæ•°ç»„
    func processVideo(
        _ video: Video,
        resumeFromState: ProcessingState? = nil
    ) async throws -> [VideoHighlight] {
        guard !isProcessing else {
            throw ProcessingError.alreadyProcessing
        }

        isProcessing = true
        defer { isProcessing = false }

        // è·å–è§†é¢‘ URL
        let videoURL = getVideoURL(for: video)
        let asset = AVAsset(url: videoURL)

        // åŠ è½½è§†é¢‘ä¿¡æ¯
        let duration = try await asset.load(.duration).seconds
        let tracks = try await asset.load(.tracks)

        guard let videoTrack = tracks.first(where: { $0.mediaType == .video }) else {
            throw ProcessingError.noVideoTrack
        }

        // ğŸ¯ æ™ºèƒ½é…ç½®é€‰æ‹© + ğŸ” å¯ç”¨éŸ³é¢‘è¯Šæ–­æ¨¡å¼
        let sampleRate = try? await asset.load(.tracks).first(where: { $0.mediaType == .audio })?.load(.naturalTimeScale)
        let audioTrack = try? await asset.load(.tracks).first(where: { $0.mediaType == .audio })
        let channelCount = (try? await audioTrack?.load(.formatDescriptions).first.map { formatDesc -> Int in
            let formatDescRef = formatDesc as! CMAudioFormatDescription
            let basicDesc = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescRef)
            return Int(basicDesc?.pointee.mChannelsPerFrame ?? 1)
        }) ?? 1

        // ğŸ¯ æ­¥éª¤1ï¼šå¿«é€ŸéŸ³é¢‘é¢„æ‰«æï¼ˆåˆ†æå‰ 30 ç§’éŸ³é¢‘ç‰¹å¾ï¼‰
        let quickScanDuration = min(30.0, duration)
        let quickScanTimeRange = CMTimeRange(
            start: .zero,
            duration: CMTime(seconds: quickScanDuration, preferredTimescale: 600)
        )

        let quickScanResult = try? await audioAnalyzer.analyzeAudio(
            from: asset,
            timeRange: quickScanTimeRange
        )

        // ğŸ¯ æ­¥éª¤2ï¼šæ ¹æ®éŸ³é¢‘ç‰¹å¾æ™ºèƒ½é€‰æ‹©é…ç½®
        let selectedConfig = selectOptimalConfig(
            quickScanResult: quickScanResult,
            videoTitle: video.title
        )

        // ğŸ¯ æ­¥éª¤3ï¼šåº”ç”¨é€‰æ‹©çš„é…ç½®
        await audioAnalyzer.updateConfig(selectedConfig)

        // ğŸ” æ­¥éª¤4ï¼šå¯ç”¨è¯Šæ–­æ¨¡å¼
        let videoInfo = VideoDiagnosticInfo(
            fileName: video.title,
            duration: duration,
            sampleRate: Double(sampleRate ?? 44100),
            channelCount: channelCount
        )
        await audioAnalyzer.enableDiagnosticMode(videoInfo: videoInfo)
        print("ğŸ” [VideoProcessing] å·²å¯ç”¨éŸ³é¢‘è¯Šæ–­æ¨¡å¼")

        // Defer: åœ¨å¤„ç†ç»“æŸæ—¶å¯¼å‡ºè¯Šæ–­æ•°æ®
        defer {
            Task { @MainActor in
                if let diagnosticData = await audioAnalyzer.getDiagnosticData() {
                    if let fileURL = AudioDiagnosticExporter.exportToFile(
                        diagnosticData: diagnosticData,
                        videoTitle: video.title
                    ) {
                        video.audioDiagnosticDataPath = fileURL.path
                        print("âœ… [VideoProcessing] éŸ³é¢‘è¯Šæ–­æ•°æ®å·²å¯¼å‡º: \(fileURL.path)")
                    }
                }
                await audioAnalyzer.disableDiagnosticMode()
            }
        }

        // åˆå§‹åŒ–å¤„ç†çŠ¶æ€ï¼ˆå¦‚æœæ˜¯æ–°å¤„ç†ï¼‰
        if resumeFromState == nil {
            _ = stateManager.createState(
                for: video.id,
                totalDuration: duration
            )
        }

        // ç¡®å®šå¤„ç†èµ·ç‚¹
        let startTime = resumeFromState?.currentTime ?? 0.0
        var detectedRallies: [VideoHighlight] = []

        // åˆ†æ®µå¤„ç†
        let segmentDuration = config.segmentDuration
        var currentSegmentStart = startTime

        while currentSegmentStart < duration {
            let currentSegmentEnd = min(currentSegmentStart + segmentDuration, duration)

            // å¤„ç†å½“å‰æ®µ
            let ralliesInSegment = try await processSegment(
                asset: asset,
                videoTrack: videoTrack,
                video: video,
                startTime: currentSegmentStart,
                endTime: currentSegmentEnd,
                totalDuration: duration,
                currentRallyCount: detectedRallies.count
            )

            detectedRallies.append(contentsOf: ralliesInSegment)

            // ä¿å­˜å¤„ç†çŠ¶æ€ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰- è½¬æ¢ VideoHighlight ä¸º Rally
            let ralliesForState = detectedRallies.map { $0.toRally() }
            try saveProcessingState(
                videoID: video.id,
                totalDuration: duration,
                currentTime: currentSegmentEnd,
                detectedRallies: ralliesForState
            )

            currentSegmentStart = currentSegmentEnd
        }

        // æ¸…ç†å¤„ç†çŠ¶æ€
        stateManager.removeState(for: video.id)

        return detectedRallies
    }

    /// å–æ¶ˆå¤„ç†ï¼ˆå®ç° VideoProcessing åè®®ï¼‰
    func cancelProcessing() async {
        // å½“å‰å®ç°é€šè¿‡ Task å–æ¶ˆæœºåˆ¶å¤„ç†
        // æœªæ¥å¯ä»¥æ·»åŠ æ›´ç»†ç²’åº¦çš„å–æ¶ˆæ§åˆ¶
    }

    // MARK: - Private Methods - Segment Processing

    /// å¤„ç†å•ä¸ªè§†é¢‘æ®µ
    private func processSegment(
        asset: AVAsset,
        videoTrack: AVAssetTrack,
        video: Video,
        startTime: Double,
        endTime: Double,
        totalDuration: Double,
        currentRallyCount: Int
    ) async throws -> [VideoHighlight] {

        // 1ï¸âƒ£ åˆ†æéŸ³é¢‘ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        let audioAnalysisTask = Task {
            await analyzeAudioForSegment(
                asset: asset,
                startTime: startTime,
                endTime: endTime
            )
        }

        // 2ï¸âƒ£ åˆ›å»º AssetReaderï¼ˆè§†é¢‘å¸§å¤„ç†ï¼‰
        let reader = try AVAssetReader(asset: asset)

        // é…ç½®è¾“å‡ºè®¾ç½®ï¼ˆé™ä½åˆ†è¾¨ç‡ä»¥ä¼˜åŒ–å†…å­˜ï¼‰
        let outputSettings: [String: Any] = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferWidthKey as String: config.processingWidth,
            kCVPixelBufferHeightKey as String: config.processingHeight
        ]

        let trackOutput = AVAssetReaderTrackOutput(
            track: videoTrack,
            outputSettings: outputSettings
        )

        // è®¾ç½®æ—¶é—´èŒƒå›´
        let timeRange = CMTimeRange(
            start: CMTime(seconds: startTime, preferredTimescale: 600),
            end: CMTime(seconds: endTime, preferredTimescale: 600)
        )
        trackOutput.supportsRandomAccess = false

        reader.add(trackOutput)
        reader.timeRange = timeRange
        reader.startReading()

        // ç”¨äºæ£€æµ‹å›åˆçš„ä¸´æ—¶æ•°æ®
        var frameAnalysisResults: [FrameAnalysisResult] = []
        var ballAnalysisResults: [BallAnalysisResult] = []  // ç½‘çƒåˆ†æç»“æœ
        var detectedRallies: [VideoHighlight] = []
        var lastSampledTime: Double = startTime

        // è¿›åº¦æ›´æ–°èŠ‚æµ
        var lastProgressUpdateTime: Double = startTime
        var lastReportedProgress: Double = 0.0

        // é€å¸§å¤„ç†ï¼ˆä½¿ç”¨ autoreleasepool ä¼˜åŒ–å†…å­˜ï¼‰
        while reader.status == .reading {
            // ä½¿ç”¨ autoreleasepool è¯»å–å’Œæå–å¸§æ•°æ®
            let frameData: (imageBuffer: CVPixelBuffer, timestamp: Double)? = autoreleasepool {
                guard let sampleBuffer = trackOutput.copyNextSampleBuffer() else {
                    return nil
                }

                defer {
                    // ç«‹å³é‡Šæ”¾ CMSampleBuffer å†…å­˜
                    CMSampleBufferInvalidate(sampleBuffer)
                }

                // è·å–å½“å‰æ—¶é—´æˆ³
                let presentationTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
                let currentTime = CMTimeGetSeconds(presentationTime)

                // å¸§é‡‡æ ·ï¼šåªå¤„ç†æ¯ 0.5 ç§’çš„å¸§ï¼ˆ2fpsï¼‰
                guard currentTime - lastSampledTime >= config.frameSamplingInterval else {
                    return nil
                }

                lastSampledTime = currentTime

                // æå–å›¾åƒç¼“å†²åŒº
                guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
                    return nil
                }

                return (imageBuffer, currentTime)
            }

            // å¦‚æœæ²¡æœ‰æœ‰æ•ˆå¸§æ•°æ®ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯
            guard let (imageBuffer, currentTime) = frameData else {
                continue
            }

            // åœ¨ autoreleasepool å¤–è¿›è¡Œå¼‚æ­¥åˆ†æ
            if let frameResult = await analyzeFrame(imageBuffer: imageBuffer, at: currentTime) {
                frameAnalysisResults.append(frameResult)
            }

            // ç½‘çƒè¿½è¸ªåˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if let ballTracker = ballTracker {
                let ballResult = await ballTracker.analyze(pixelBuffer: imageBuffer, timestamp: currentTime)
                ballAnalysisResults.append(ballResult)
            }

            // æ¯ç§¯ç´¯ä¸€å®šæ•°é‡çš„å¸§ï¼Œå°è¯•æ£€æµ‹å›åˆï¼ˆè§†è§‰æ£€æµ‹ä½œä¸ºå¤‡é€‰ï¼‰
            // æ³¨æ„ï¼šéŸ³é¢‘èšç±»æ£€æµ‹åœ¨æ®µå¤„ç†å®Œæˆåç»Ÿä¸€è¿›è¡Œ
            if frameAnalysisResults.count >= config.rallyDetectionWindowSize {
                // è§†è§‰æ£€æµ‹ä½œä¸ºé™çº§ç­–ç•¥ï¼ˆå¦‚æœéŸ³é¢‘æ£€æµ‹å¤±è´¥ï¼‰
                if let rally = detectRallyUsingVisual(
                    from: frameAnalysisResults,
                    ballResults: ballAnalysisResults,
                    audioResult: await audioAnalysisTask.value,
                    video: video,
                    currentRallyNumber: currentRallyCount + detectedRallies.count + 1
                ) {
                    detectedRallies.append(rally)

                    // å®æ—¶å›è°ƒé€šçŸ¥æ£€æµ‹åˆ°æ–°å›åˆ
                    Task { @MainActor in
                        onRallyDetected?(rally)
                    }

                    // æ¸…ç©ºåˆ†æç»“æœï¼Œå‡†å¤‡æ£€æµ‹ä¸‹ä¸€ä¸ªå›åˆ
                    frameAnalysisResults.removeAll(keepingCapacity: true)
                    ballAnalysisResults.removeAll(keepingCapacity: true)
                } else {
                    // ä¿ç•™æœ€è¿‘çš„å¸§ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£
                    if frameAnalysisResults.count > config.rallyDetectionWindowSize * 2 {
                        frameAnalysisResults.removeFirst(config.rallyDetectionWindowSize)
                        // åŒæ­¥æ¸…ç†ç½‘çƒåˆ†æç»“æœ
                        if ballAnalysisResults.count > config.rallyDetectionWindowSize * 2 {
                            ballAnalysisResults.removeFirst(config.rallyDetectionWindowSize)
                        }
                    }
                }
            }

            // æ›´æ–°è¿›åº¦ï¼ˆèŠ‚æµä¼˜åŒ–ï¼šå‡å°‘UIæ›´æ–°é¢‘ç‡ï¼‰
            let segmentProgress = (currentTime - startTime) / (endTime - startTime)
            let overallProgress = currentTime / totalDuration

            // åªåœ¨æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ä¹‹ä¸€æ—¶æ›´æ–°UIï¼š
            // 1. è·ç¦»ä¸Šæ¬¡æ›´æ–°è¶…è¿‡ progressUpdateInterval ç§’
            // 2. è¿›åº¦å˜åŒ–è¶…è¿‡ progressUpdateThreshold
            let timeSinceLastUpdate = currentTime - lastProgressUpdateTime
            let progressDelta = abs(overallProgress - lastReportedProgress)

            if timeSinceLastUpdate >= config.progressUpdateInterval ||
               progressDelta >= config.progressUpdateThreshold {

                lastProgressUpdateTime = currentTime
                lastReportedProgress = overallProgress

                Task { @MainActor in
                    let progress = ProcessingProgress(
                        currentTime: currentTime,
                        totalDuration: totalDuration,
                        segmentProgress: segmentProgress,
                        overallProgress: overallProgress,
                        detectedRalliesCount: currentRallyCount + detectedRallies.count,
                        currentOperation: "å¤„ç†ä¸­: \(formatTime(currentTime)) / \(formatTime(totalDuration))"
                    )
                    onProgressUpdate?(progress)
                }
            }
        }

        // æ£€æŸ¥è¯»å–çŠ¶æ€
        if reader.status == .failed {
            throw ProcessingError.readFailed(reader.error)
        }

        // æ®µå¤„ç†å®Œæˆåï¼Œä½¿ç”¨éŸ³é¢‘èšç±»è¿›è¡Œæœ€ç»ˆæ£€æµ‹
        // å…ˆæ›´æ–°è¿›åº¦ï¼Œè¡¨ç¤ºå¸§å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç­‰å¾…éŸ³é¢‘åˆ†æ
        let frameProcessingProgress = (endTime / totalDuration) * 0.9 // å¸§å¤„ç†å 90%è¿›åº¦
        Task { @MainActor in
            let progress = ProcessingProgress(
                currentTime: endTime,
                totalDuration: totalDuration,
                segmentProgress: 1.0,
                overallProgress: frameProcessingProgress,
                detectedRalliesCount: currentRallyCount + detectedRallies.count,
                currentOperation: "åˆ†æéŸ³é¢‘ä¸­..."
            )
            onProgressUpdate?(progress)
        }
        
        let finalAudioResult = await audioAnalysisTask.value
        
        print("ğŸ” [VideoProcessing] æ®µéŸ³é¢‘åˆ†æå®Œæˆ: æ£€æµ‹åˆ° \(finalAudioResult.hitSounds.count) ä¸ªéŸ³é¢‘å³°å€¼")
        if !finalAudioResult.hitSounds.isEmpty {
            print("ğŸ” [VideoProcessing] å³°å€¼æ—¶é—´èŒƒå›´: \(String(format: "%.2f", finalAudioResult.hitSounds.first!.time))s - \(String(format: "%.2f", finalAudioResult.hitSounds.last!.time))s")
            print("ğŸ” [VideoProcessing] å³°å€¼ç½®ä¿¡åº¦èŒƒå›´: \(String(format: "%.2f", finalAudioResult.hitSounds.map { $0.confidence }.min() ?? 0)) - \(String(format: "%.2f", finalAudioResult.hitSounds.map { $0.confidence }.max() ?? 0))")
        }
        
        let audioRallies = await rallyDetectionEngine.detectRallies(audioResult: finalAudioResult)
        print("ğŸ” [VideoProcessing] éŸ³é¢‘èšç±»æ£€æµ‹åˆ° \(audioRallies.count) ä¸ªå›åˆ")
        
        // å°†éŸ³é¢‘æ£€æµ‹åˆ°çš„å›åˆè½¬æ¢ä¸ºVideoHighlight
        var audioDetectedRallies: [VideoHighlight] = []
        for (index, rally) in audioRallies.enumerated() {
            print("ğŸ” [VideoProcessing] å›åˆ #\(index + 1): \(String(format: "%.2f", rally.startTime))s - \(String(format: "%.2f", rally.endTime))s (æ®µèŒƒå›´: \(String(format: "%.2f", startTime))s - \(String(format: "%.2f", endTime))s)")
            
            // æ£€æŸ¥å›åˆæ˜¯å¦åœ¨å½“å‰æ®µçš„æ—¶é—´èŒƒå›´å†…ï¼ˆæ”¾å®½æ¡ä»¶ï¼šåªè¦å›åˆä¸æ®µæœ‰é‡å å³å¯ï¼‰
            let rallyOverlapsSegment = rally.startTime < endTime && rally.endTime > startTime
            
            if rallyOverlapsSegment {
                print("âœ… [VideoProcessing] å›åˆ #\(index + 1) ä¸æ®µé‡å ï¼Œæ·»åŠ åˆ°ç»“æœ")
                let highlight = createHighlightFromRally(
                    rally: rally,
                    video: video,
                    currentRallyNumber: currentRallyCount + detectedRallies.count + audioDetectedRallies.count + index + 1,
                    frames: frameAnalysisResults,
                    ballResults: ballAnalysisResults,
                    audioResult: finalAudioResult
                )
                audioDetectedRallies.append(highlight)
            } else {
                print("âŒ [VideoProcessing] å›åˆ #\(index + 1) ä¸åœ¨æ®µèŒƒå›´å†…ï¼Œè·³è¿‡")
            }
        }

        // å¦‚æœéŸ³é¢‘æ£€æµ‹åˆ°å›åˆï¼Œä¼˜å…ˆä½¿ç”¨éŸ³é¢‘ç»“æœï¼›å¦åˆ™ä½¿ç”¨è§†è§‰æ£€æµ‹ç»“æœ
        if !audioDetectedRallies.isEmpty {
            print("âœ… [VideoProcessing] ä½¿ç”¨éŸ³é¢‘æ£€æµ‹ç»“æœ: \(audioDetectedRallies.count) ä¸ªå›åˆ")
            return audioDetectedRallies
        }

        print("âš ï¸ [VideoProcessing] éŸ³é¢‘æ£€æµ‹æœªæ‰¾åˆ°å›åˆï¼Œä½¿ç”¨è§†è§‰æ£€æµ‹ç»“æœ: \(detectedRallies.count) ä¸ªå›åˆ")
        
        // æ›´æ–°æœ€ç»ˆè¿›åº¦
        let finalProgress = min(endTime / totalDuration, 1.0)
        Task { @MainActor in
            let progress = ProcessingProgress(
                currentTime: endTime,
                totalDuration: totalDuration,
                segmentProgress: 1.0,
                overallProgress: finalProgress,
                detectedRalliesCount: currentRallyCount + detectedRallies.count,
                currentOperation: "æ®µå¤„ç†å®Œæˆ"
            )
            onProgressUpdate?(progress)
        }
        
        return detectedRallies
    }

    // MARK: - Private Methods - Audio Analysis

    /// åˆ†æè§†é¢‘æ®µçš„éŸ³é¢‘
    /// - Parameters:
    ///   - asset: è§†é¢‘èµ„æº
    ///   - startTime: å¼€å§‹æ—¶é—´
    ///   - endTime: ç»“æŸæ—¶é—´
    /// - Returns: éŸ³é¢‘åˆ†æç»“æœ
    private func analyzeAudioForSegment(
        asset: AVAsset,
        startTime: Double,
        endTime: Double
    ) async -> AudioAnalysisResult {
        do {
            let timeRange = CMTimeRange(
                start: CMTime(seconds: startTime, preferredTimescale: 600),
                end: CMTime(seconds: endTime, preferredTimescale: 600)
            )

            let result = try await audioAnalyzer.analyzeAudio(
                from: asset,
                timeRange: timeRange
            )

            print("âœ… [VideoProcessing] éŸ³é¢‘åˆ†ææˆåŠŸ: æ£€æµ‹åˆ° \(result.hitSounds.count) ä¸ªå³°å€¼")
            return result
        } catch {
            // éŸ³é¢‘åˆ†æå¤±è´¥æ—¶è¿”å›ç©ºç»“æœ
            print("âš ï¸ éŸ³é¢‘åˆ†æå¤±è´¥: \(error.localizedDescription)")
            
            // é™çº§ç­–ç•¥ï¼šå°è¯•ä½¿ç”¨æ›´å®½æ¾çš„é…ç½®é‡è¯•
            print("ğŸ”„ å°è¯•ä½¿ç”¨å®½æ¾é…ç½®é‡è¯•éŸ³é¢‘åˆ†æ...")
            do {
                let timeRange = CMTimeRange(
                    start: CMTime(seconds: startTime, preferredTimescale: 600),
                    end: CMTime(seconds: endTime, preferredTimescale: 600)
                )
                // è¿™é‡Œå¯ä»¥å°è¯•ä½¿ç”¨æ›´å®½æ¾çš„éŸ³é¢‘åˆ†æé…ç½®
                let result = try await audioAnalyzer.analyzeAudio(
                    from: asset,
                    timeRange: timeRange
                )
                print("âœ… é™çº§éŸ³é¢‘åˆ†ææˆåŠŸï¼Œæ£€æµ‹åˆ° \(result.hitSounds.count) ä¸ªå³°å€¼")
                return result
            } catch {
                print("âŒ é™çº§éŸ³é¢‘åˆ†æä¹Ÿå¤±è´¥: \(error.localizedDescription)")
                return AudioAnalysisResult(hitSounds: [])
            }
        }
    }

    // MARK: - Private Methods - Frame Analysis

    /// åˆ†æå•å¸§å›¾åƒï¼ˆä½¿ç”¨ Vision æ¡†æ¶ï¼‰
    /// - Parameters:
    ///   - imageBuffer: å›¾åƒåƒç´ ç¼“å†²åŒº
    ///   - timestamp: æ—¶é—´æˆ³
    /// - Returns: å¸§åˆ†æç»“æœ
    private func analyzeFrame(
        imageBuffer: CVPixelBuffer,
        at timestamp: Double
    ) async -> FrameAnalysisResult? {

        // ä½¿ç”¨ VisionAnalyzer è¿›è¡Œå§¿æ€æ£€æµ‹
        do {
            let result = try await visionAnalyzer.analyzeFrame(
                pixelBuffer: imageBuffer,
                timestamp: timestamp
            )
            return result
        } catch {
            // Vision åˆ†æå¤±è´¥æ—¶ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼ˆç®€å•è¿åŠ¨æ£€æµ‹ï¼‰
            print("âš ï¸ Vision åˆ†æå¤±è´¥: \(error.localizedDescription)ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
            return fallbackAnalysis(imageBuffer: imageBuffer, timestamp: timestamp)
        }
    }

    /// é™çº§æ–¹æ¡ˆï¼šç®€å•çš„è¿åŠ¨æ£€æµ‹ï¼ˆå½“ Vision å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
    private func fallbackAnalysis(
        imageBuffer: CVPixelBuffer,
        timestamp: Double
    ) -> FrameAnalysisResult {
        // ä½¿ç”¨ç®€å•çš„åƒç´ å˜åŒ–æ£€æµ‹
        let movementIntensity = Double.random(in: 0.2...0.5) // æ¨¡æ‹Ÿæ£€æµ‹

        let hasPerson = movementIntensity > config.thresholds.movementIntensityThreshold
        let confidence = min(1.0, movementIntensity / 0.8)

        return FrameAnalysisResult(
            hasPerson: hasPerson,
            confidence: confidence,
            movementIntensity: movementIntensity,
            keyPoints: nil,
            timestamp: timestamp
        )
    }

    // MARK: - Private Methods - Rally Detection

    /// ä½¿ç”¨è§†è§‰ç‰¹å¾æ£€æµ‹å›åˆï¼ˆé™çº§ç­–ç•¥ï¼‰
    private func detectRallyUsingVisual(
        from frames: [FrameAnalysisResult],
        ballResults: [BallAnalysisResult],
        audioResult: AudioAnalysisResult,
        video: Video,
        currentRallyNumber: Int
    ) -> VideoHighlight? {

        // ä¼˜å…ˆç­–ç•¥ï¼šå¦‚æœæœ‰ç½‘çƒè¿½è¸ªæ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨ç½‘çƒæ£€æµ‹
        let useBallTracking = !ballResults.isEmpty

        // æŸ¥æ‰¾è¿ç»­çš„é«˜å¼ºåº¦è¿åŠ¨åŒºé—´
        var rallyStart: Double?
        var rallyEnd: Double?
        var intensitySum: Double = 0
        var validFrameCount: Int = 0
        var ballTrajectoryPoints: [BallTrajectoryPoint] = []
        var ballDetectionCount: Int = 0

        // åˆå¹¶å¤„ç†ï¼šä½¿ç”¨ç½‘çƒæ£€æµ‹æˆ–å§¿æ€æ£€æµ‹
        if useBallTracking {
            // ç½‘çƒè¿½è¸ªæ¨¡å¼
            for ballResult in ballResults {
                // åˆ¤æ–­æ˜¯å¦æœ‰ç§»åŠ¨çš„ç½‘çƒ
                let hasMovingBall = ballResult.primaryBall?.isMoving(threshold: 0.05) ?? false

                if hasMovingBall {
                    if rallyStart == nil {
                        rallyStart = ballResult.timestamp
                    }
                    rallyEnd = ballResult.timestamp

                    // ç´¯ç§¯ç½‘çƒè½¨è¿¹æ•°æ®
                    if let primaryBall = ballResult.primaryBall {
                        ballDetectionCount += 1
                        let trajectoryPoint = BallTrajectoryPoint(
                            timestamp: primaryBall.timestamp,
                            position: CodablePoint(primaryBall.center),
                            velocity: CodableVector(primaryBall.velocity),
                            confidence: primaryBall.confidence
                        )
                        ballTrajectoryPoints.append(trajectoryPoint)
                    }

                    // ä½¿ç”¨ç½‘çƒç§»åŠ¨å¼ºåº¦ä½œä¸ºintensity
                    let ballIntensity = ballResult.primaryBall?.movementMagnitude ?? 0.0
                    intensitySum += ballIntensity
                    validFrameCount += 1
                } else {
                    // æ£€æµ‹åˆ°ç½‘çƒåœæ­¢ï¼Œåˆ¤æ–­æ˜¯å¦å›åˆç»“æŸ
                    if let start = rallyStart,
                       let end = rallyEnd,
                       end - start >= config.thresholds.minimumRallyDuration {

                        return createHighlight(
                            start: start,
                            end: end,
                            intensitySum: intensitySum,
                            validFrameCount: validFrameCount,
                            audioResult: audioResult,
                            frames: frames,
                            video: video,
                            currentRallyNumber: currentRallyNumber,
                            ballTrajectoryPoints: ballTrajectoryPoints,
                            ballDetectionCount: ballDetectionCount
                        )
                    }

                    // é‡ç½®
                    rallyStart = nil
                    rallyEnd = nil
                    intensitySum = 0
                    validFrameCount = 0
                    ballTrajectoryPoints.removeAll(keepingCapacity: true)
                    ballDetectionCount = 0
                }
            }
        } else {
            // é™çº§åˆ°å§¿æ€æ£€æµ‹æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            for frame in frames {
                if frame.movementIntensity > config.thresholds.movementIntensityThreshold {
                if rallyStart == nil {
                    rallyStart = frame.timestamp
                }
                rallyEnd = frame.timestamp
                    intensitySum += frame.movementIntensity
                    validFrameCount += 1
                } else {
                    // æ£€æµ‹åˆ°ä½å¼ºåº¦å¸§ï¼Œåˆ¤æ–­æ˜¯å¦å›åˆç»“æŸ
                    if let start = rallyStart,
                       let end = rallyEnd,
                       end - start >= config.thresholds.minimumRallyDuration {

                        return createHighlight(
                            start: start,
                            end: end,
                            intensitySum: intensitySum,
                            validFrameCount: validFrameCount,
                            audioResult: audioResult,
                            frames: frames,
                            video: video,
                            currentRallyNumber: currentRallyNumber,
                            ballTrajectoryPoints: [],
                            ballDetectionCount: 0
                        )
                    }

                    // é‡ç½®æ£€æµ‹çŠ¶æ€
                    rallyStart = nil
                    rallyEnd = nil
                    intensitySum = 0
                    validFrameCount = 0
                }
            }
        }

        return nil
    }

    /// ä»Rallyå¯¹è±¡åˆ›å»ºVideoHighlightï¼ˆéŸ³é¢‘èšç±»ç»“æœï¼‰
    private func createHighlightFromRally(
        rally: Rally,
        video: Video,
        currentRallyNumber: Int,
        frames: [FrameAnalysisResult],
        ballResults: [BallAnalysisResult],
        audioResult: AudioAnalysisResult? = nil
    ) -> VideoHighlight {
        
        // è®¡ç®—ç²¾å½©åº¦è¯„åˆ†
        let excitementScore = calculateExcitementScoreFromRally(
            rally: rally,
            frames: frames
        )

        // åˆ›å»º VideoHighlight
        let highlight = VideoHighlight(
            video: video,
            rallyNumber: currentRallyNumber,
            startTime: rally.startTime,
            endTime: rally.endTime,
            excitementScore: excitementScore,
            videoFilePath: video.originalFilePath,
            type: classifyRallyType(duration: rally.duration, intensity: rally.metadata.avgMovementIntensity)
        )

        highlight.rallyDescription = "å›åˆ #\(currentRallyNumber)"
        highlight.detectionConfidence = min(1.0, rally.metadata.avgMovementIntensity > 0 ? rally.metadata.avgMovementIntensity : 0.6)
        
        // è®¾ç½®å…ƒæ•°æ®ï¼ˆä»Rallyä¸­è·å–ï¼‰
        var metadata = rally.metadata
        
        // ä»éŸ³é¢‘åˆ†æç»“æœä¸­æå–æœ¬å›åˆçš„éŸ³é¢‘å³°å€¼æ—¶é—´ç‚¹
        if let audioResult = audioResult {
            // æå–è¯¥å›åˆæ—¶é—´èŒƒå›´å†…çš„éŸ³é¢‘å³°å€¼æ—¶é—´ç‚¹
            let peakTimestamps = audioResult.hitSounds
                .filter { $0.time >= rally.startTime && $0.time <= rally.endTime }
                .map { $0.time }
            metadata.audioPeakTimestamps = peakTimestamps.isEmpty ? nil : peakTimestamps
        }
        
        highlight.metadata = metadata

        // æ·»åŠ ç½‘çƒè½¨è¿¹æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if let ballTrajectory = rally.ballTrajectory {
            highlight.ballTrajectoryData = ballTrajectory
        }

        return highlight
    }
    
    /// æå–å›åˆå¯¹åº”çš„éŸ³é¢‘åˆ†æç»“æœï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰
    private func extractAudioResultForRally(rally: Rally, finalAudioResult: AudioAnalysisResult) -> AudioAnalysisResult? {
        // è¿‡æ»¤å‡ºè¯¥å›åˆæ—¶é—´èŒƒå›´å†…çš„éŸ³é¢‘å³°å€¼
        let relevantPeaks = finalAudioResult.hitSounds.filter { peak in
            peak.time >= rally.startTime && peak.time <= rally.endTime
        }
        return AudioAnalysisResult(hitSounds: relevantPeaks)
    }

    /// ä»Rallyè®¡ç®—ç²¾å½©åº¦è¯„åˆ†
    private func calculateExcitementScoreFromRally(
        rally: Rally,
        frames: [FrameAnalysisResult]
    ) -> Double {
        // ä½¿ç”¨Rallyçš„å…ƒæ•°æ®è®¡ç®—ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        let duration = rally.duration
        let intensity = rally.metadata.avgMovementIntensity > 0 ? 
            rally.metadata.avgMovementIntensity : 
            (frames.isEmpty ? 0.5 : frames.map(\.movementIntensity).reduce(0, +) / Double(frames.count))
        let hasAudioPeaks = rally.metadata.hasAudioPeaks

        return calculateExcitementScore(
            duration: duration,
            intensity: intensity,
            hasAudioPeaks: hasAudioPeaks
        )
    }

    /// åˆ›å»ºVideoHighlightå¯¹è±¡ï¼ˆç»Ÿä¸€çš„è¾…åŠ©æ–¹æ³•ï¼‰
    private func createHighlight(
        start: Double,
        end: Double,
        intensitySum: Double,
        validFrameCount: Int,
        audioResult: AudioAnalysisResult,
        frames: [FrameAnalysisResult],
        video: Video,
        currentRallyNumber: Int,
        ballTrajectoryPoints: [BallTrajectoryPoint],
        ballDetectionCount: Int
    ) -> VideoHighlight {

        // æ£€æŸ¥æ­¤æ—¶é—´æ®µå†…æ˜¯å¦æœ‰å‡»çƒå£°ï¼ˆå¢å¼ºæ£€æµ‹å‡†ç¡®æ€§ï¼‰
        let hasAudioPeaks = audioResult.hitSounds.contains { peak in
            peak.time >= start && peak.time <= end && peak.confidence > config.thresholds.audioHitConfidence
        }

        // è®¡ç®—å¹³å‡å¼ºåº¦
        let avgIntensity = validFrameCount > 0 ? intensitySum / Double(validFrameCount) : 0.0

        // è®¡ç®—ç²¾å½©åº¦è¯„åˆ†
        let excitementScore = calculateExcitementScore(
            duration: end - start,
            intensity: avgIntensity,
            hasAudioPeaks: hasAudioPeaks
        )

        // åˆ›å»º VideoHighlight
        let highlight = VideoHighlight(
            video: video,
            rallyNumber: currentRallyNumber,
            startTime: max(0, start - 1.0), // å‰ç½® 1 ç§’ç¼“å†²
            endTime: min(video.duration, end + 1.0), // åç½® 1 ç§’ç¼“å†²
            excitementScore: excitementScore,
            videoFilePath: video.originalFilePath,
            type: classifyRallyType(duration: end - start, intensity: avgIntensity)
        )

        highlight.rallyDescription = "å›åˆ #\(currentRallyNumber)"
        highlight.detectionConfidence = min(1.0, avgIntensity)

        // æ›´æ–°æ£€æµ‹å…ƒæ•°æ®
        var metadata = DetectionMetadata(
            maxMovementIntensity: frames.map(\.movementIntensity).max() ?? 0.0,
            avgMovementIntensity: avgIntensity,
            hasAudioPeaks: hasAudioPeaks,
            poseConfidenceAvg: frames.isEmpty ? 0.0 : frames.map(\.confidence).reduce(0, +) / Double(frames.count),
            estimatedHitCount: nil,
            playerCount: nil,
            audioPeakTimestamps: nil
        )
        
        // æå–è¯¥å›åˆæ—¶é—´èŒƒå›´å†…çš„éŸ³é¢‘å³°å€¼æ—¶é—´ç‚¹
        let peakTimestamps = audioResult.hitSounds
            .filter { $0.time >= start && $0.time <= end && $0.confidence > config.thresholds.audioHitConfidence }
            .map { $0.time }
        metadata.audioPeakTimestamps = peakTimestamps.isEmpty ? nil : peakTimestamps
        
        highlight.metadata = metadata

        // æ·»åŠ ç½‘çƒè½¨è¿¹æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if ballDetectionCount > 0 {
            let avgBallConfidence = ballTrajectoryPoints.isEmpty ? 0.0 :
                ballTrajectoryPoints.map(\.confidence).reduce(0, +) / Double(ballTrajectoryPoints.count)
            let maxVelocity = ballTrajectoryPoints.map(\.velocity.magnitude).max() ?? 0.0
            let avgVelocity = ballTrajectoryPoints.isEmpty ? 0.0 :
                ballTrajectoryPoints.map(\.velocity.magnitude).reduce(0, +) / Double(ballTrajectoryPoints.count)

            // è®¡ç®—æ€»ç§»åŠ¨è·ç¦»
            var totalDistance: Double = 0.0
            for i in 1..<ballTrajectoryPoints.count {
                let p1 = ballTrajectoryPoints[i-1].position
                let p2 = ballTrajectoryPoints[i].position
                let dx = p2.x - p1.x
                let dy = p2.y - p1.y
                totalDistance += sqrt(dx * dx + dy * dy)
            }

            highlight.ballTrajectoryData = BallTrajectoryData(
                trajectoryPoints: ballTrajectoryPoints,
                detectionCount: ballDetectionCount,
                avgConfidence: avgBallConfidence,
                maxVelocity: maxVelocity,
                avgVelocity: avgVelocity,
                totalDistance: totalDistance
            )
        }

        return highlight
    }

    /// è®¡ç®—ç²¾å½©åº¦è¯„åˆ†
    private func calculateExcitementScore(
        duration: Double,
        intensity: Double,
        hasAudioPeaks: Bool
    ) -> Double {
        // ç»¼åˆè€ƒè™‘æ—¶é•¿ã€å¼ºåº¦å’ŒéŸ³é¢‘
        let durationScore = min(1.0, duration / 20.0) * 30 // æœ€é•¿ 20 ç§’ç»™ 30 åˆ†
        let intensityScore = intensity * 50 // å¼ºåº¦æœ€é«˜ç»™ 50 åˆ†
        let audioScore = hasAudioPeaks ? 20.0 : 0.0 // æœ‰å‡»çƒå£°åŠ  20 åˆ†
        return min(100, durationScore + intensityScore + audioScore)
    }

    /// åˆ†ç±»å›åˆç±»å‹
    private func classifyRallyType(duration: Double, intensity: Double) -> String {
        if duration > 15 {
            return "å¤šå›åˆå¯¹æ‹‰"
        } else if intensity > 0.7 {
            return "é«˜å¼ºåº¦å¯¹æŠ—"
        } else if duration > 8 {
            return "ä¸­é•¿å›åˆ"
        } else {
            return "å¿«é€Ÿäº¤é”‹"
        }
    }

    // MARK: - Private Methods - State Management

    /// ä¿å­˜å¤„ç†çŠ¶æ€
    private func saveProcessingState(
        videoID: UUID,
        totalDuration: Double,
        currentTime: Double,
        detectedRallies: [Rally]
    ) throws {
        // ä½¿ç”¨æ³¨å…¥çš„ stateManager ç»Ÿä¸€ç®¡ç†çŠ¶æ€
        stateManager.updateState(for: videoID) { state in
            state.currentTime = currentTime
            state.detectedRallies = detectedRallies
            // segmentIndex å¯ä»¥ä» currentTime è®¡ç®—ï¼Œè¿™é‡Œä¿æŒç®€å•
            state.currentSegmentIndex = Int(currentTime / config.segmentDuration)
        }
    }

    // MARK: - Helper Methods

    private func getVideoURL(for video: Video) -> URL {
        FileManager.default
            .urls(for: .documentDirectory, in: .userDomainMask)[0]
            .appendingPathComponent(video.originalFilePath)
    }

    private func formatTime(_ seconds: Double) -> String {
        let minutes = Int(seconds) / 60
        let secs = Int(seconds) % 60
        return String(format: "%d:%02d", minutes, secs)
    }

    // MARK: - Smart Configuration Selection

    /// æ ¹æ®éŸ³é¢‘å¿«é€Ÿæ‰«æç»“æœæ™ºèƒ½é€‰æ‹©æœ€ä¼˜é…ç½®
    /// - Parameters:
    ///   - quickScanResult: å¿«é€Ÿæ‰«æç»“æœï¼ˆå‰30ç§’éŸ³é¢‘åˆ†æï¼‰
    ///   - videoTitle: è§†é¢‘æ ‡é¢˜ï¼ˆç”¨äºå¯å‘å¼åˆ¤æ–­ï¼‰
    /// - Returns: é€‰æ‹©çš„éŸ³é¢‘åˆ†æé…ç½®
    private func selectOptimalConfig(
        quickScanResult: AudioAnalysisResult?,
        videoTitle: String
    ) -> AudioAnalysisConfiguration {
        // é»˜è®¤é…ç½®
        var selectedConfig = AudioAnalysisConfiguration.default

        // å¦‚æœå¿«é€Ÿæ‰«æå¤±è´¥æˆ–æ— ç»“æœï¼Œä½¿ç”¨å¯å‘å¼è§„åˆ™
        guard let scanResult = quickScanResult, !scanResult.hitSounds.isEmpty else {
            print("âš™ï¸ [ConfigSelection] å¿«é€Ÿæ‰«ææ— ç»“æœï¼Œä½¿ç”¨å¯å‘å¼è§„åˆ™")

            // å¯å‘å¼è§„åˆ™ï¼šæ£€æŸ¥è§†é¢‘æ ‡é¢˜ä¸­æ˜¯å¦åŒ…å«"æ‰‹æœº"ã€"ç°åœº"ç­‰å…³é”®è¯
            let lowerTitle = videoTitle.lowercased()
            if lowerTitle.contains("æ‰‹æœº") || lowerTitle.contains("ç°åœº") ||
               lowerTitle.contains("mobile") || lowerTitle.contains("phone") {
                selectedConfig = .mobileRecording
                print("âš™ï¸ [ConfigSelection] æ ¹æ®æ ‡é¢˜å…³é”®è¯é€‰æ‹©: mobile_recording")
            } else {
                print("âš™ï¸ [ConfigSelection] ä½¿ç”¨é»˜è®¤é…ç½®: default")
            }
            return selectedConfig
        }

        // è®¡ç®—æ‰«æç»“æœçš„éŸ³é¢‘ç‰¹å¾
        let hitAmplitudes = scanResult.hitSounds.map { $0.amplitude }
        let hitConfidences = scanResult.hitSounds.map { $0.confidence }

        guard !hitAmplitudes.isEmpty else {
            print("âš™ï¸ [ConfigSelection] æ‰«æç»“æœæ— å³°å€¼ï¼Œä½¿ç”¨ mobile_recording é…ç½®")
            return .mobileRecording
        }

        // è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        let avgAmplitude = hitAmplitudes.reduce(0.0, +) / Double(hitAmplitudes.count)
        let maxAmplitude = hitAmplitudes.max() ?? 0.0
        let medianAmplitude = hitAmplitudes.sorted()[hitAmplitudes.count / 2]

        let avgConfidence = hitConfidences.reduce(0.0, +) / Double(hitConfidences.count)

        print("ğŸ“Š [ConfigSelection] å¿«é€Ÿæ‰«æç»Ÿè®¡:")
        print("   - æ£€æµ‹åˆ° \(scanResult.hitSounds.count) ä¸ªå‡»çƒå£°")
        print("   - å¹³å‡æŒ¯å¹…: \(String(format: "%.3f", avgAmplitude))")
        print("   - ä¸­ä½æŒ¯å¹…: \(String(format: "%.3f", medianAmplitude))")
        print("   - æœ€å¤§æŒ¯å¹…: \(String(format: "%.3f", maxAmplitude))")
        print("   - å¹³å‡ç½®ä¿¡åº¦: \(String(format: "%.3f", avgConfidence))")

        // å†³ç­–é€»è¾‘ï¼šåŸºäºéŸ³é¢‘ç‰¹å¾é€‰æ‹©é…ç½®
        if medianAmplitude < 0.22 || avgAmplitude < 0.20 {
            // éŸ³é‡åä½ â†’ ä½¿ç”¨ mobile_recording é…ç½®
            selectedConfig = .mobileRecording
            print("âš™ï¸ [ConfigSelection] æ£€æµ‹åˆ°ä½éŸ³é‡ â†’ é€‰æ‹©: mobile_recording")
            print("   åŸå› : ä¸­ä½æŒ¯å¹… \(String(format: "%.3f", medianAmplitude)) < 0.22 æˆ–å¹³å‡æŒ¯å¹… \(String(format: "%.3f", avgAmplitude)) < 0.20")

        } else if avgConfidence < 0.60 && scanResult.hitSounds.count < 5 {
            // ç½®ä¿¡åº¦ä½ä¸”æ£€æµ‹æ•°é‡å°‘ â†’ ä½¿ç”¨ lenient é…ç½®
            selectedConfig = .lenient
            print("âš™ï¸ [ConfigSelection] æ£€æµ‹åˆ°ä½ç½®ä¿¡åº¦ä¸”æ•°é‡å°‘ â†’ é€‰æ‹©: lenient")
            print("   åŸå› : å¹³å‡ç½®ä¿¡åº¦ \(String(format: "%.3f", avgConfidence)) < 0.60 ä¸”æ£€æµ‹æ•°é‡ \(scanResult.hitSounds.count) < 5")

        } else if maxAmplitude > 0.6 && avgConfidence > 0.75 {
            // éŸ³è´¨å¾ˆå¥½ â†’ ä½¿ç”¨ strict é…ç½®
            selectedConfig = .strict
            print("âš™ï¸ [ConfigSelection] æ£€æµ‹åˆ°é«˜è´¨é‡éŸ³é¢‘ â†’ é€‰æ‹©: strict")
            print("   åŸå› : æœ€å¤§æŒ¯å¹… \(String(format: "%.3f", maxAmplitude)) > 0.6 ä¸”å¹³å‡ç½®ä¿¡åº¦ \(String(format: "%.3f", avgConfidence)) > 0.75")

        } else {
            // å…¶ä»–æƒ…å†µ â†’ ä½¿ç”¨é»˜è®¤é…ç½®
            selectedConfig = .default
            print("âš™ï¸ [ConfigSelection] éŸ³é¢‘ç‰¹å¾é€‚ä¸­ â†’ é€‰æ‹©: default")
        }

        return selectedConfig
    }
}

// MARK: - Supporting Types

/// å¤„ç†é…ç½®
struct ProcessingConfiguration {
    /// åˆ†æ®µæ—¶é•¿ï¼ˆç§’ï¼‰- æ¯æ¬¡å¤„ç† 2 åˆ†é’Ÿ
    let segmentDuration: Double = 120.0

    /// å¤„ç†åˆ†è¾¨ç‡ï¼ˆé™ä½åˆ†è¾¨ç‡ä»¥ä¼˜åŒ–å†…å­˜ï¼‰
    let processingWidth: Int = 640
    let processingHeight: Int = 360

    /// å¸§é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰- 2fps
    let frameSamplingInterval: Double = 0.5

    /// è¿›åº¦æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰- ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé™ä½UIæ›´æ–°é¢‘ç‡
    let progressUpdateInterval: Double = 4.0  // 2ç§’ â†’ 4ç§’

    /// è¿›åº¦å˜åŒ–é˜ˆå€¼ - ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šåªåœ¨å˜åŒ–è¶…è¿‡æ­¤å€¼æ—¶æ›´æ–°
    let progressUpdateThreshold: Double = 0.05  // 2% â†’ 5%

    /// å›åˆæ£€æµ‹çª—å£å¤§å°ï¼ˆå¸§æ•°ï¼‰
    let rallyDetectionWindowSize: Int = 20

    /// æ£€æµ‹é˜ˆå€¼
    let thresholds = DetectionThresholds.default
}

/// å¤„ç†è¿›åº¦
struct ProcessingProgress {
    /// å½“å‰å¤„ç†æ—¶é—´
    let currentTime: Double

    /// æ€»æ—¶é•¿
    let totalDuration: Double

    /// å½“å‰æ®µè¿›åº¦ï¼ˆ0-1ï¼‰
    let segmentProgress: Double

    /// æ€»ä½“è¿›åº¦ï¼ˆ0-1ï¼‰
    let overallProgress: Double

    /// å·²æ£€æµ‹å›åˆæ•°
    let detectedRalliesCount: Int

    /// å½“å‰æ“ä½œæè¿°
    let currentOperation: String
}

/// å¤„ç†é”™è¯¯
enum ProcessingError: LocalizedError {
    case alreadyProcessing
    case noVideoTrack
    case readFailed(Error?)
    case analysisRailed

    var errorDescription: String? {
        switch self {
        case .alreadyProcessing:
            return "è§†é¢‘å¤„ç†æ­£åœ¨è¿›è¡Œä¸­"
        case .noVideoTrack:
            return "æ— æ³•æ‰¾åˆ°è§†é¢‘è½¨é“"
        case .readFailed(let error):
            return "è¯»å–è§†é¢‘å¤±è´¥: \(error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")"
        case .analysisRailed:
            return "è§†é¢‘åˆ†æå¤±è´¥"
        }
    }
}
