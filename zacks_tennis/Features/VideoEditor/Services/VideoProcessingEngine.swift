//
//  VideoProcessingEngine.swift
//  zacks_tennis
//
//  æ ¸å¿ƒè§†é¢‘å¤„ç†å¼•æ“ - ä¼˜åŒ–ç‰ˆæœ¬
//  æ”¯æŒåˆ†æ®µå¤„ç†ã€å†…å­˜ä¼˜åŒ–ã€æ–­ç‚¹ç»­ä¼ 
//

import Foundation
import AVFoundation
import CoreImage
import UIKit
import SwiftData

/// è§†é¢‘å¤„ç†å¼•æ“ - æ ¸å¿ƒå¤„ç†é€»è¾‘
@MainActor
@Observable
final class VideoProcessingEngine: VideoProcessing {

    // MARK: - Properties

    /// å¤„ç†è¿›åº¦å›è°ƒ
    var onProgressUpdate: ((ProcessingProgress) -> Void)?

    /// æ–°å›åˆæ£€æµ‹å›è°ƒï¼ˆå®æ—¶æµå¼æ›´æ–°ï¼‰
    var onRallyDetected: ((VideoHighlight) -> Void)?

    /// æ˜¯å¦æ­£åœ¨å¤„ç†
    private(set) var isProcessing = false

    /// Vision åˆ†æå™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let visionAnalyzer: any FrameAnalyzing

    /// éŸ³é¢‘åˆ†æå™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let audioAnalyzer: any AudioAnalyzing

    /// çŠ¶æ€ç®¡ç†å™¨ï¼ˆåè®®ç±»å‹ - æ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    private let stateManager: any ProcessingStateManaging

    // MARK: - Constants

    /// å¤„ç†é…ç½®
    private let config = ProcessingConfiguration()

    // MARK: - Initialization

    /// åˆå§‹åŒ–å¤„ç†å¼•æ“ï¼ˆæ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
    /// - Parameters:
    ///   - visionAnalyzer: Vision åˆ†æå™¨
    ///   - audioAnalyzer: éŸ³é¢‘åˆ†æå™¨
    ///   - stateManager: çŠ¶æ€ç®¡ç†å™¨
    init(
        visionAnalyzer: any FrameAnalyzing,
        audioAnalyzer: any AudioAnalyzing,
        stateManager: any ProcessingStateManaging
    ) {
        self.visionAnalyzer = visionAnalyzer
        self.audioAnalyzer = audioAnalyzer
        self.stateManager = stateManager
    }

    /// ä¾¿åˆ©åˆå§‹åŒ–å™¨ - ä½¿ç”¨é»˜è®¤å®ç°
    convenience init() {
        self.init(
            visionAnalyzer: VisionAnalyzer(),
            audioAnalyzer: AudioAnalyzer(),
            stateManager: ProcessingStateManager.shared
        )
    }

    // MARK: - Public Methods

    /// å¤„ç†è§†é¢‘å¹¶æ£€æµ‹å›åˆï¼ˆåè®®å®ç°ï¼‰
    /// - Parameter video: è¦å¤„ç†çš„è§†é¢‘æ¨¡å‹
    /// - Returns: æ£€æµ‹åˆ°çš„å›åˆæ•°ç»„
    func processVideo(_ video: Video) async throws -> [VideoHighlight] {
        return try await processVideo(video, resumeFromState: nil)
    }

    /// å¤„ç†è§†é¢‘å¹¶æ£€æµ‹å›åˆï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    /// - Parameters:
    ///   - video: è¦å¤„ç†çš„è§†é¢‘æ¨¡å‹
    ///   - resumeFromState: å¯é€‰çš„æ¢å¤çŠ¶æ€ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
    /// - Returns: æ£€æµ‹åˆ°çš„å›åˆæ•°ç»„
    func processVideo(
        _ video: Video,
        resumeFromState: ProcessingState? = nil
    ) async throws -> [VideoHighlight] {
        guard !isProcessing else {
            throw ProcessingError.alreadyProcessing
        }

        isProcessing = true
        defer { isProcessing = false }

        // è·å–è§†é¢‘ URL
        let videoURL = getVideoURL(for: video)
        let asset = AVAsset(url: videoURL)

        // åŠ è½½è§†é¢‘ä¿¡æ¯
        let duration = try await asset.load(.duration).seconds
        let tracks = try await asset.load(.tracks)

        guard let videoTrack = tracks.first(where: { $0.mediaType == .video }) else {
            throw ProcessingError.noVideoTrack
        }

        // åˆå§‹åŒ–å¤„ç†çŠ¶æ€ï¼ˆå¦‚æœæ˜¯æ–°å¤„ç†ï¼‰
        if resumeFromState == nil {
            _ = stateManager.createState(
                for: video.id,
                totalDuration: duration
            )
        }

        // ç¡®å®šå¤„ç†èµ·ç‚¹
        let startTime = resumeFromState?.currentTime ?? 0.0
        var detectedRallies: [VideoHighlight] = []

        // åˆ†æ®µå¤„ç†
        let segmentDuration = config.segmentDuration
        var currentSegmentStart = startTime

        while currentSegmentStart < duration {
            let currentSegmentEnd = min(currentSegmentStart + segmentDuration, duration)

            // å¤„ç†å½“å‰æ®µ
            let ralliesInSegment = try await processSegment(
                asset: asset,
                videoTrack: videoTrack,
                video: video,
                startTime: currentSegmentStart,
                endTime: currentSegmentEnd,
                totalDuration: duration,
                currentRallyCount: detectedRallies.count
            )

            detectedRallies.append(contentsOf: ralliesInSegment)

            // ä¿å­˜å¤„ç†çŠ¶æ€ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰- è½¬æ¢ VideoHighlight ä¸º Rally
            let ralliesForState = detectedRallies.map { $0.toRally() }
            try saveProcessingState(
                videoID: video.id,
                totalDuration: duration,
                currentTime: currentSegmentEnd,
                detectedRallies: ralliesForState
            )

            currentSegmentStart = currentSegmentEnd
        }

        // æ¸…ç†å¤„ç†çŠ¶æ€
        stateManager.removeState(for: video.id)

        return detectedRallies
    }

    /// å–æ¶ˆå¤„ç†ï¼ˆå®ç° VideoProcessing åè®®ï¼‰
    func cancelProcessing() async {
        // å½“å‰å®ç°é€šè¿‡ Task å–æ¶ˆæœºåˆ¶å¤„ç†
        // æœªæ¥å¯ä»¥æ·»åŠ æ›´ç»†ç²’åº¦çš„å–æ¶ˆæ§åˆ¶
    }

    // MARK: - Private Methods - Segment Processing

    /// å¤„ç†å•ä¸ªè§†é¢‘æ®µ
    private func processSegment(
        asset: AVAsset,
        videoTrack: AVAssetTrack,
        video: Video,
        startTime: Double,
        endTime: Double,
        totalDuration: Double,
        currentRallyCount: Int
    ) async throws -> [VideoHighlight] {

        // 1ï¸âƒ£ åˆ†æéŸ³é¢‘ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        let audioAnalysisTask = Task {
            await analyzeAudioForSegment(
                asset: asset,
                startTime: startTime,
                endTime: endTime
            )
        }

        // 2ï¸âƒ£ åˆ›å»º AssetReaderï¼ˆè§†é¢‘å¸§å¤„ç†ï¼‰
        let reader = try AVAssetReader(asset: asset)

        // é…ç½®è¾“å‡ºè®¾ç½®ï¼ˆé™ä½åˆ†è¾¨ç‡ä»¥ä¼˜åŒ–å†…å­˜ï¼‰
        let outputSettings: [String: Any] = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferWidthKey as String: config.processingWidth,
            kCVPixelBufferHeightKey as String: config.processingHeight
        ]

        let trackOutput = AVAssetReaderTrackOutput(
            track: videoTrack,
            outputSettings: outputSettings
        )

        // è®¾ç½®æ—¶é—´èŒƒå›´
        let timeRange = CMTimeRange(
            start: CMTime(seconds: startTime, preferredTimescale: 600),
            end: CMTime(seconds: endTime, preferredTimescale: 600)
        )
        trackOutput.supportsRandomAccess = false

        reader.add(trackOutput)
        reader.timeRange = timeRange
        reader.startReading()

        // ç”¨äºæ£€æµ‹å›åˆçš„ä¸´æ—¶æ•°æ®
        var frameAnalysisResults: [FrameAnalysisResult] = []
        var detectedRallies: [VideoHighlight] = []
        var lastSampledTime: Double = startTime

        // è¿›åº¦æ›´æ–°èŠ‚æµ
        var lastProgressUpdateTime: Double = startTime
        var lastReportedProgress: Double = 0.0

        // é€å¸§å¤„ç†ï¼ˆä½¿ç”¨ autoreleasepool ä¼˜åŒ–å†…å­˜ï¼‰
        while reader.status == .reading {
            // ä½¿ç”¨ autoreleasepool è¯»å–å’Œæå–å¸§æ•°æ®
            let frameData: (imageBuffer: CVPixelBuffer, timestamp: Double)? = autoreleasepool {
                guard let sampleBuffer = trackOutput.copyNextSampleBuffer() else {
                    return nil
                }

                defer {
                    // ç«‹å³é‡Šæ”¾ CMSampleBuffer å†…å­˜
                    CMSampleBufferInvalidate(sampleBuffer)
                }

                // è·å–å½“å‰æ—¶é—´æˆ³
                let presentationTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
                let currentTime = CMTimeGetSeconds(presentationTime)

                // å¸§é‡‡æ ·ï¼šåªå¤„ç†æ¯ 0.5 ç§’çš„å¸§ï¼ˆ2fpsï¼‰
                guard currentTime - lastSampledTime >= config.frameSamplingInterval else {
                    return nil
                }

                lastSampledTime = currentTime

                // æå–å›¾åƒç¼“å†²åŒº
                guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
                    return nil
                }

                return (imageBuffer, currentTime)
            }

            // å¦‚æœæ²¡æœ‰æœ‰æ•ˆå¸§æ•°æ®ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯
            guard let (imageBuffer, currentTime) = frameData else {
                continue
            }

            // åœ¨ autoreleasepool å¤–è¿›è¡Œå¼‚æ­¥åˆ†æ
            if let frameResult = await analyzeFrame(imageBuffer: imageBuffer, at: currentTime) {
                frameAnalysisResults.append(frameResult)
            }

            // æ¯ç§¯ç´¯ä¸€å®šæ•°é‡çš„å¸§ï¼Œå°è¯•æ£€æµ‹å›åˆ
            if frameAnalysisResults.count >= config.rallyDetectionWindowSize {
                // ç­‰å¾…éŸ³é¢‘åˆ†æå®Œæˆï¼ˆå¦‚æœè¿˜æ²¡å®Œæˆï¼‰
                let audioResult = await audioAnalysisTask.value

                if let rally = detectRally(
                    from: frameAnalysisResults,
                    audioResult: audioResult,
                    video: video,
                    currentRallyNumber: currentRallyCount + detectedRallies.count + 1
                ) {
                    detectedRallies.append(rally)

                    // å®æ—¶å›è°ƒé€šçŸ¥æ£€æµ‹åˆ°æ–°å›åˆ
                    Task { @MainActor in
                        onRallyDetected?(rally)
                    }

                    // æ¸…ç©ºåˆ†æç»“æœï¼Œå‡†å¤‡æ£€æµ‹ä¸‹ä¸€ä¸ªå›åˆ
                    frameAnalysisResults.removeAll(keepingCapacity: true)
                } else {
                    // ä¿ç•™æœ€è¿‘çš„å¸§ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£
                    if frameAnalysisResults.count > config.rallyDetectionWindowSize * 2 {
                        frameAnalysisResults.removeFirst(config.rallyDetectionWindowSize)
                    }
                }
            }

            // æ›´æ–°è¿›åº¦ï¼ˆèŠ‚æµä¼˜åŒ–ï¼šå‡å°‘UIæ›´æ–°é¢‘ç‡ï¼‰
            let segmentProgress = (currentTime - startTime) / (endTime - startTime)
            let overallProgress = currentTime / totalDuration

            // åªåœ¨æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ä¹‹ä¸€æ—¶æ›´æ–°UIï¼š
            // 1. è·ç¦»ä¸Šæ¬¡æ›´æ–°è¶…è¿‡ progressUpdateInterval ç§’
            // 2. è¿›åº¦å˜åŒ–è¶…è¿‡ progressUpdateThreshold
            let timeSinceLastUpdate = currentTime - lastProgressUpdateTime
            let progressDelta = abs(overallProgress - lastReportedProgress)

            if timeSinceLastUpdate >= config.progressUpdateInterval ||
               progressDelta >= config.progressUpdateThreshold {

                lastProgressUpdateTime = currentTime
                lastReportedProgress = overallProgress

                Task { @MainActor in
                    let progress = ProcessingProgress(
                        currentTime: currentTime,
                        totalDuration: totalDuration,
                        segmentProgress: segmentProgress,
                        overallProgress: overallProgress,
                        detectedRalliesCount: currentRallyCount + detectedRallies.count,
                        currentOperation: "å¤„ç†ä¸­: \(formatTime(currentTime)) / \(formatTime(totalDuration))"
                    )
                    onProgressUpdate?(progress)
                }
            }
        }

        // æ£€æŸ¥è¯»å–çŠ¶æ€
        if reader.status == .failed {
            throw ProcessingError.readFailed(reader.error)
        }

        return detectedRallies
    }

    // MARK: - Private Methods - Audio Analysis

    /// åˆ†æè§†é¢‘æ®µçš„éŸ³é¢‘
    /// - Parameters:
    ///   - asset: è§†é¢‘èµ„æº
    ///   - startTime: å¼€å§‹æ—¶é—´
    ///   - endTime: ç»“æŸæ—¶é—´
    /// - Returns: éŸ³é¢‘åˆ†æç»“æœ
    private func analyzeAudioForSegment(
        asset: AVAsset,
        startTime: Double,
        endTime: Double
    ) async -> AudioAnalysisResult {
        do {
            let timeRange = CMTimeRange(
                start: CMTime(seconds: startTime, preferredTimescale: 600),
                end: CMTime(seconds: endTime, preferredTimescale: 600)
            )

            let result = try await audioAnalyzer.analyzeAudio(
                from: asset,
                timeRange: timeRange
            )

            return result
        } catch {
            // éŸ³é¢‘åˆ†æå¤±è´¥æ—¶è¿”å›ç©ºç»“æœ
            print("âš ï¸ éŸ³é¢‘åˆ†æå¤±è´¥: \(error.localizedDescription)")
            return AudioAnalysisResult(hitSounds: [])
        }
    }

    // MARK: - Private Methods - Frame Analysis

    /// åˆ†æå•å¸§å›¾åƒï¼ˆä½¿ç”¨ Vision æ¡†æ¶ï¼‰
    /// - Parameters:
    ///   - imageBuffer: å›¾åƒåƒç´ ç¼“å†²åŒº
    ///   - timestamp: æ—¶é—´æˆ³
    /// - Returns: å¸§åˆ†æç»“æœ
    private func analyzeFrame(
        imageBuffer: CVPixelBuffer,
        at timestamp: Double
    ) async -> FrameAnalysisResult? {

        // ä½¿ç”¨ VisionAnalyzer è¿›è¡Œå§¿æ€æ£€æµ‹
        do {
            let result = try await visionAnalyzer.analyzeFrame(
                pixelBuffer: imageBuffer,
                timestamp: timestamp
            )
            return result
        } catch {
            // Vision åˆ†æå¤±è´¥æ—¶ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼ˆç®€å•è¿åŠ¨æ£€æµ‹ï¼‰
            print("âš ï¸ Vision åˆ†æå¤±è´¥: \(error.localizedDescription)ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
            return fallbackAnalysis(imageBuffer: imageBuffer, timestamp: timestamp)
        }
    }

    /// é™çº§æ–¹æ¡ˆï¼šç®€å•çš„è¿åŠ¨æ£€æµ‹ï¼ˆå½“ Vision å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
    private func fallbackAnalysis(
        imageBuffer: CVPixelBuffer,
        timestamp: Double
    ) -> FrameAnalysisResult {
        // ä½¿ç”¨ç®€å•çš„åƒç´ å˜åŒ–æ£€æµ‹
        let movementIntensity = Double.random(in: 0.2...0.5) // æ¨¡æ‹Ÿæ£€æµ‹

        let hasPerson = movementIntensity > config.thresholds.movementIntensityThreshold
        let confidence = min(1.0, movementIntensity / 0.8)

        return FrameAnalysisResult(
            hasPerson: hasPerson,
            confidence: confidence,
            movementIntensity: movementIntensity,
            keyPoints: nil,
            timestamp: timestamp
        )
    }

    // MARK: - Private Methods - Rally Detection

    /// ä»å¸§åˆ†æç»“æœä¸­æ£€æµ‹å›åˆ
    private func detectRally(
        from frames: [FrameAnalysisResult],
        audioResult: AudioAnalysisResult,
        video: Video,
        currentRallyNumber: Int
    ) -> VideoHighlight? {

        // æŸ¥æ‰¾è¿ç»­çš„é«˜å¼ºåº¦è¿åŠ¨åŒºé—´
        var rallyStart: Double?
        var rallyEnd: Double?
        var intensitySum: Double = 0
        var validFrameCount: Int = 0
        var hasAudioPeaks = false

        for frame in frames {
            if frame.movementIntensity > config.thresholds.movementIntensityThreshold {
                if rallyStart == nil {
                    rallyStart = frame.timestamp
                }
                rallyEnd = frame.timestamp
                intensitySum += frame.movementIntensity
                validFrameCount += 1
            } else {
                // æ£€æµ‹åˆ°ä½å¼ºåº¦å¸§ï¼Œåˆ¤æ–­æ˜¯å¦å›åˆç»“æŸ
                if let start = rallyStart,
                   let end = rallyEnd,
                   end - start >= config.thresholds.minimumRallyDuration {

                    // æ£€æŸ¥æ­¤æ—¶é—´æ®µå†…æ˜¯å¦æœ‰å‡»çƒå£°ï¼ˆå¢å¼ºæ£€æµ‹å‡†ç¡®æ€§ï¼‰
                    hasAudioPeaks = audioResult.hitSounds.contains { peak in
                        peak.time >= start && peak.time <= end && peak.confidence > config.thresholds.audioHitConfidence
                    }

                    // æ‰¾åˆ°æœ‰æ•ˆå›åˆ
                    let avgIntensity = intensitySum / Double(validFrameCount)
                    let excitementScore = calculateExcitementScore(
                        duration: end - start,
                        intensity: avgIntensity,
                        hasAudioPeaks: hasAudioPeaks
                    )

                    let highlight = VideoHighlight(
                        video: video,
                        rallyNumber: currentRallyNumber,
                        startTime: max(0, start - 1.0), // å‰ç½® 1 ç§’ç¼“å†²
                        endTime: min(video.duration, end + 1.0), // åç½® 1 ç§’ç¼“å†²
                        excitementScore: excitementScore,
                        videoFilePath: video.originalFilePath, // ä½¿ç”¨åŸè§†é¢‘è·¯å¾„
                        type: classifyRallyType(duration: end - start, intensity: avgIntensity)
                    )

                    highlight.rallyDescription = "å›åˆ #\(currentRallyNumber)"
                    highlight.detectionConfidence = min(1.0, avgIntensity)

                    // æ›´æ–°æ£€æµ‹å…ƒæ•°æ®
                    highlight.metadata = DetectionMetadata(
                        maxMovementIntensity: frames.map(\.movementIntensity).max() ?? 0.0,
                        avgMovementIntensity: avgIntensity,
                        hasAudioPeaks: hasAudioPeaks,
                        poseConfidenceAvg: frames.map(\.confidence).reduce(0, +) / Double(frames.count)
                    )

                    return highlight
                }

                // é‡ç½®æ£€æµ‹çŠ¶æ€
                rallyStart = nil
                rallyEnd = nil
                intensitySum = 0
                validFrameCount = 0
                hasAudioPeaks = false
            }
        }

        return nil
    }

    /// è®¡ç®—ç²¾å½©åº¦è¯„åˆ†
    private func calculateExcitementScore(
        duration: Double,
        intensity: Double,
        hasAudioPeaks: Bool
    ) -> Double {
        // ç»¼åˆè€ƒè™‘æ—¶é•¿ã€å¼ºåº¦å’ŒéŸ³é¢‘
        let durationScore = min(1.0, duration / 20.0) * 30 // æœ€é•¿ 20 ç§’ç»™ 30 åˆ†
        let intensityScore = intensity * 50 // å¼ºåº¦æœ€é«˜ç»™ 50 åˆ†
        let audioScore = hasAudioPeaks ? 20.0 : 0.0 // æœ‰å‡»çƒå£°åŠ  20 åˆ†
        return min(100, durationScore + intensityScore + audioScore)
    }

    /// åˆ†ç±»å›åˆç±»å‹
    private func classifyRallyType(duration: Double, intensity: Double) -> String {
        if duration > 15 {
            return "å¤šå›åˆå¯¹æ‹‰"
        } else if intensity > 0.7 {
            return "é«˜å¼ºåº¦å¯¹æŠ—"
        } else if duration > 8 {
            return "ä¸­é•¿å›åˆ"
        } else {
            return "å¿«é€Ÿäº¤é”‹"
        }
    }

    // MARK: - Private Methods - State Management

    /// ä¿å­˜å¤„ç†çŠ¶æ€
    private func saveProcessingState(
        videoID: UUID,
        totalDuration: Double,
        currentTime: Double,
        detectedRallies: [Rally]
    ) throws {
        // ä½¿ç”¨æ³¨å…¥çš„ stateManager ç»Ÿä¸€ç®¡ç†çŠ¶æ€
        stateManager.updateState(for: videoID) { state in
            state.currentTime = currentTime
            state.detectedRallies = detectedRallies
            // segmentIndex å¯ä»¥ä» currentTime è®¡ç®—ï¼Œè¿™é‡Œä¿æŒç®€å•
            state.currentSegmentIndex = Int(currentTime / config.segmentDuration)
        }
    }

    // MARK: - Helper Methods

    private func getVideoURL(for video: Video) -> URL {
        FileManager.default
            .urls(for: .documentDirectory, in: .userDomainMask)[0]
            .appendingPathComponent(video.originalFilePath)
    }

    private func formatTime(_ seconds: Double) -> String {
        let minutes = Int(seconds) / 60
        let secs = Int(seconds) % 60
        return String(format: "%d:%02d", minutes, secs)
    }
}

// MARK: - Supporting Types

/// å¤„ç†é…ç½®
struct ProcessingConfiguration {
    /// åˆ†æ®µæ—¶é•¿ï¼ˆç§’ï¼‰- æ¯æ¬¡å¤„ç† 2 åˆ†é’Ÿ
    let segmentDuration: Double = 120.0

    /// å¤„ç†åˆ†è¾¨ç‡ï¼ˆé™ä½åˆ†è¾¨ç‡ä»¥ä¼˜åŒ–å†…å­˜ï¼‰
    let processingWidth: Int = 640
    let processingHeight: Int = 360

    /// å¸§é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰- 2fps
    let frameSamplingInterval: Double = 0.5

    /// è¿›åº¦æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰- ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé™ä½UIæ›´æ–°é¢‘ç‡
    let progressUpdateInterval: Double = 4.0  // 2ç§’ â†’ 4ç§’

    /// è¿›åº¦å˜åŒ–é˜ˆå€¼ - ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šåªåœ¨å˜åŒ–è¶…è¿‡æ­¤å€¼æ—¶æ›´æ–°
    let progressUpdateThreshold: Double = 0.05  // 2% â†’ 5%

    /// å›åˆæ£€æµ‹çª—å£å¤§å°ï¼ˆå¸§æ•°ï¼‰
    let rallyDetectionWindowSize: Int = 20

    /// æ£€æµ‹é˜ˆå€¼
    let thresholds = DetectionThresholds.default
}

/// å¤„ç†è¿›åº¦
struct ProcessingProgress {
    /// å½“å‰å¤„ç†æ—¶é—´
    let currentTime: Double

    /// æ€»æ—¶é•¿
    let totalDuration: Double

    /// å½“å‰æ®µè¿›åº¦ï¼ˆ0-1ï¼‰
    let segmentProgress: Double

    /// æ€»ä½“è¿›åº¦ï¼ˆ0-1ï¼‰
    let overallProgress: Double

    /// å·²æ£€æµ‹å›åˆæ•°
    let detectedRalliesCount: Int

    /// å½“å‰æ“ä½œæè¿°
    let currentOperation: String
}

/// å¤„ç†é”™è¯¯
enum ProcessingError: LocalizedError {
    case alreadyProcessing
    case noVideoTrack
    case readFailed(Error?)
    case analysisRailed

    var errorDescription: String? {
        switch self {
        case .alreadyProcessing:
            return "è§†é¢‘å¤„ç†æ­£åœ¨è¿›è¡Œä¸­"
        case .noVideoTrack:
            return "æ— æ³•æ‰¾åˆ°è§†é¢‘è½¨é“"
        case .readFailed(let error):
            return "è¯»å–è§†é¢‘å¤±è´¥: \(error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")"
        case .analysisRailed:
            return "è§†é¢‘åˆ†æå¤±è´¥"
        }
    }
}
